---
layout: post
title: "Statistical analysis construction: The mason R package"
category:
    - R
tag:
    - R
    - Packages
---



Most analyses follow a similar pattern to how construction/engineering projects
are developed: design -> add specifications -> construction -> (optional) add to
the design and specs and continue construction -> cleaning, scrubbing, and
polishing. I created the `mason` package to try to emulate this process and make
it easier to do analyses in a consistent and 'tidy' format.

## Basic command flow

The general command flow for using `mason` is:

1. Start the design of a blueprint for the analysis by specifying which
statistical technique to use in your analysis (`design()`).
2. Add settings/options to the blueprint for the methods of the statistics
(`add_settings()`).
3. Add the variables you want to run the statistics on (`add_variables()`).
These variables include the $y$ variables (outcomes), the $x$ variables
(predictors), covariates, and interaction variables.
4. Using the blueprint, construct the 'mason project' (stats analysis) so that
the results are generated (`construct()`).
5. Sometimes analyses are too big for one first pass, from blueprint to
construction, and needs to add more to the blueprint. Use `add_variables()` or
`add_settings()` after the `construct()` to add to the existing
results.
6. When you are ready, make the 'mason project' cleaned up by scrubbing it down
and polishing it up (`scrub()` and `polish_*()` commands). The results are now
ready for further presentation in a figure or table!

### Example usage

Let's go over an example analysis. We'll use `glm` for a simple linear
regression. Let's use the built-in `swiss` dataset. A quick peek at it shows:


{% highlight r %}
head(swiss)
{% endhighlight %}



{% highlight text %}
#>              Fertility Agriculture Examination Education Catholic
#> Courtelary        80.2        17.0          15        12     9.96
#> Delemont          83.1        45.1           6         9    84.84
#> Franches-Mnt      92.5        39.7           5         5    93.40
#> Moutier           85.8        36.5          12         7    33.77
#> Neuveville        76.9        43.5          17        15     5.16
#> Porrentruy        76.1        35.3           9         7    90.57
#>              Infant.Mortality
#> Courtelary               22.2
#> Delemont                 22.2
#> Franches-Mnt             20.2
#> Moutier                  20.3
#> Neuveville               20.6
#> Porrentruy               26.6
{% endhighlight %}

Ok, let's say we want to several models. We are interested in `Fertility` and
`Infant.Mortality` as outcomes and `Education` and `Agriculture` as potential
predictors. We also want to control for `Catholic`. This setup means we have
four potential models to analyze. With mason this is relatively easy. Analyses
in mason are essentially separated into a blueprint phase and a construction
phase. Since any structure or building always needs a blueprint, let's get that
started.


{% highlight r %}
library(mason)
design(swiss, 'glm')
{% endhighlight %}



{% highlight text %}
#> # Analysis for glm is still under construction. 
#> # Showing data right now:
#> # A tibble: 47 x 6
#>   Fertility Agriculture Examination Education Catholic Infant.Mortality
#>       <dbl>       <dbl>       <int>     <int>    <dbl>            <dbl>
#> 1      80.2        17.0          15        12     9.96             22.2
#> 2      83.1        45.1           6         9    84.84             22.2
#> 3      92.5        39.7           5         5    93.40             20.2
#> 4      85.8        36.5          12         7    33.77             20.3
#> 5      76.9        43.5          17        15     5.16             20.6
#> 6      76.1        35.3           9         7    90.57             26.6
#> # ... with 41 more rows
{% endhighlight %}

So far, all we've done is created a blueprint of the analysis, but it doesn't
contain much. Let's add some settings to the blueprint. mason was designed to
make use of the `%>%` pipes from the package `magrittr` (also found in `dplyr`),
so let's load up `magrittr`!


{% highlight r %}
library(magrittr)
dp <- design(swiss, 'glm') %>% 
    add_settings(family = gaussian()) %>% 
    add_variables('yvars', c('Fertility', 'Infant.Mortality')) %>% 
    add_variables('xvars', c('Education', 'Agriculture'))
dp
{% endhighlight %}



{% highlight text %}
#> # Analysis for glm is still under construction. 
#> # Showing data right now:
#> # A tibble: 47 x 6
#>   Fertility Agriculture Examination Education Catholic Infant.Mortality
#>       <dbl>       <dbl>       <int>     <int>    <dbl>            <dbl>
#> 1      80.2        17.0          15        12     9.96             22.2
#> 2      83.1        45.1           6         9    84.84             22.2
#> 3      92.5        39.7           5         5    93.40             20.2
#> 4      85.8        36.5          12         7    33.77             20.3
#> 5      76.9        43.5          17        15     5.16             20.6
#> 6      76.1        35.3           9         7    90.57             26.6
#> # ... with 41 more rows
{% endhighlight %}

You'll notice that each time, the only thing that is printed to the console is
the dataset. That's because we haven't constructed the analysis yet! We are
still in the blueprint phase, so nothing new has been added! Since we have two
outcomes and two predictors, we have a total of four models to analysis.
Normally we would need to run each of the models separately. However, if we simply
list the outcomes and the predictors in mason, it will compute a model for each
combination! Next, we can construct the analysis using `construct()`.


{% highlight r %}
dp <- construct(dp)
dp
{% endhighlight %}



{% highlight text %}
#> # Analysis for glm constructed but has not been scrubbed. 
#> # Here is a peek at the results:
#> # A tibble: 8 x 10
#>             Yterms      Xterms        term     estimate  std.error
#>              <chr>       <chr>       <chr>        <dbl>      <dbl>
#> 1        Fertility Agriculture (Intercept) 60.304375228 4.25125562
#> 2        Fertility Agriculture XtermValues  0.194201749 0.07671176
#> 3        Fertility   Education (Intercept) 79.610058532 2.10409711
#> 4        Fertility   Education XtermValues -0.862350293 0.14484472
#> 5 Infant.Mortality Agriculture (Intercept) 20.337954766 1.05754318
#> 6 Infant.Mortality Agriculture XtermValues -0.007805071 0.01908283
#> # ... with 2 more rows, and 5 more variables: statistic <dbl>,
#> #   p.value <dbl>, conf.low <dbl>, conf.high <dbl>, sample.size <int>
{% endhighlight %}

Cool! This is the unadjusted model, without any covariates. We said we wanted to
adjust for `Catholic`. But let's say we want to keep the unadjusted analysis
too. Since we have 'finished' the analysis by cleaning it up, we can still add
to the blueprint.


{% highlight r %}
dp2 <- dp %>%
    add_variables('covariates', 'Catholic') %>% 
    construct()
dp2
{% endhighlight %}



{% highlight text %}
#> # Analysis for glm constructed but has not been scrubbed. 
#> # Here is a peek at the results:
#> # A tibble: 20 x 10
#>             Yterms      Xterms        term     estimate  std.error
#>              <chr>       <chr>       <chr>        <dbl>      <dbl>
#> 1        Fertility Agriculture (Intercept) 60.304375228 4.25125562
#> 2        Fertility Agriculture XtermValues  0.194201749 0.07671176
#> 3        Fertility   Education (Intercept) 79.610058532 2.10409711
#> 4        Fertility   Education XtermValues -0.862350293 0.14484472
#> 5 Infant.Mortality Agriculture (Intercept) 20.337954766 1.05754318
#> 6 Infant.Mortality Agriculture XtermValues -0.007805071 0.01908283
#> # ... with 14 more rows, and 5 more variables: statistic <dbl>,
#> #   p.value <dbl>, conf.low <dbl>, conf.high <dbl>, sample.size <int>
{% endhighlight %}

We now have two models in the results. We're happy with them, so let's clean it
up using the `scrub()` function. 


{% highlight r %}
dp_clean <- dp2 %>% 
    scrub()
{% endhighlight %}

All `scrub()` does is remove any extra specs in the attributes and sets the
results as the main dataset. We can put it all as a single pipe chain:


{% highlight r %}
swiss %>% 
    design('glm') %>% 
    add_settings() %>% 
    add_variables('yvars', c('Fertility', 'Infant.Mortality')) %>% 
    add_variables('xvars', c('Education', 'Agriculture')) %>% 
    construct() %>% 
    add_variables('covariates', 'Catholic') %>% 
    construct() %>% 
    scrub()
{% endhighlight %}



{% highlight text %}
#> # A tibble: 20 x 10
#>              Yterms      Xterms        term     estimate  std.error
#>               <chr>       <chr>       <chr>        <dbl>      <dbl>
#> 1         Fertility Agriculture (Intercept) 60.304375228 4.25125562
#> 2         Fertility Agriculture     <-Xterm  0.194201749 0.07671176
#> 3         Fertility   Education (Intercept) 79.610058532 2.10409711
#> 4         Fertility   Education     <-Xterm -0.862350293 0.14484472
#> 5  Infant.Mortality Agriculture (Intercept) 20.337954766 1.05754318
#> 6  Infant.Mortality Agriculture     <-Xterm -0.007805071 0.01908283
#> 7  Infant.Mortality   Education (Intercept) 20.272865076 0.65272716
#> 8  Infant.Mortality   Education     <-Xterm -0.030086548 0.04493333
#> 9         Fertility Agriculture (Intercept) 59.863923712 3.98753957
#> 10        Fertility Agriculture     <-Xterm  0.109528109 0.07848208
#> 11        Fertility Agriculture    Catholic  0.114962125 0.04273900
#> 12        Fertility   Education (Intercept) 74.233689201 2.35197061
#> 13        Fertility   Education     <-Xterm -0.788329259 0.12929324
#> 14        Fertility   Education    Catholic  0.110920955 0.02980965
#> 15 Infant.Mortality Agriculture (Intercept) 20.274208854 1.04449977
#> 16 Infant.Mortality Agriculture     <-Xterm -0.020059765 0.02055767
#> 17 Infant.Mortality Agriculture    Catholic  0.016638302 0.01119509
#> 18 Infant.Mortality   Education (Intercept) 19.717357317 0.82539716
#> 19 Infant.Mortality   Education     <-Xterm -0.022438401 0.04537398
#> 20 Infant.Mortality   Education    Catholic  0.011460792 0.01046136
#> # ... with 5 more variables: statistic <dbl>, p.value <dbl>,
#> #   conf.low <dbl>, conf.high <dbl>, sample.size <int>
{% endhighlight %}

There are also additional `polish_*` type commands that are more or less simply
wrappers around commands that you may do on the results dataset, like filtering
or renaming. The list of polish commands can be found in `?mason::polish`.

> Note: This is a slightly modified version of the introduction vignette for
mason
([`vignette('mason')`](https://htmlpreview.github.io/?https://github.com/lwjohnst86/mason/blob/master/vignettes/mason.html)
from version 0.2.5). I also created this package to make
my analyses easier. So most of the statistics that have been implemented were chosen
because that's what I use. If you would like a particular statistical method
included, please fill out an [Issue](https://github.com/lwjohnst86/mason/issues)
and I will try to implement it!
